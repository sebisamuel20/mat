{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic modules\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "# ml modules\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>BS</th>\n",
       "      <th>BodyTemp</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>RiskLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>13.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>140</td>\n",
       "      <td>85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>6.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
       "0   25         130           80  15.0      98.0         86  high risk\n",
       "1   35         140           90  13.0      98.0         70  high risk\n",
       "2   29          90           70   8.0     100.0         80  high risk\n",
       "3   30         140           85   7.0      98.0         70  high risk\n",
       "4   35         120           60   6.1      98.0         76   low risk"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/maternal_health_risk_new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RiskLevel\n",
       "high risk    112\n",
       "low risk     106\n",
       "mid risk     106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = RandomUnderSampler(sampling_strategy= 'majority', random_state= 42)\n",
    "df, df['RiskLevel'] = sampler.fit_resample(df, df['RiskLevel'])\n",
    "df['RiskLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = df.select_dtypes(exclude='O').columns\n",
    "cat_features = df.select_dtypes(include= 'O').columns\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "oh_encoder = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"StandardScaler\", num_transformer, num_features)\n",
    "        # (\"OneHotEncoder\", oh_encoder, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns = ['RiskLevel'], axis =1)\n",
    "y = df['RiskLevel']\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((259, 6), (65, 6))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluator(true, pred):\n",
    "    pre = precision_score(true, pred, average= 'macro')\n",
    "    recall = recall_score(true, pred, average= 'macro')\n",
    "    f1 = f1_score(true, pred, average= 'macro')\n",
    "\n",
    "    return pre, recall, f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Precision: 0.5738\n",
      "- Recall: 0.5799\n",
      "- F1 Score 0.5749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.69      0.69      0.69        86\n",
      "    low risk       0.58      0.66      0.62        86\n",
      "    mid risk       0.46      0.39      0.42        87\n",
      "\n",
      "    accuracy                           0.58       259\n",
      "   macro avg       0.57      0.58      0.57       259\n",
      "weighted avg       0.57      0.58      0.57       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.5387\n",
      "- Recall: 0.5561\n",
      "- F1 score: 0.5446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.81      0.81      0.81        26\n",
      "    low risk       0.54      0.65      0.59        20\n",
      "    mid risk       0.27      0.21      0.24        19\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.54      0.56      0.54        65\n",
      "weighted avg       0.57      0.58      0.57        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Precision: 0.5515\n",
      "- Recall: 0.5537\n",
      "- F1 Score 0.5142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.80      0.62      0.70        86\n",
      "    low risk       0.49      0.90      0.63        86\n",
      "    mid risk       0.36      0.15      0.21        87\n",
      "\n",
      "    accuracy                           0.55       259\n",
      "   macro avg       0.55      0.55      0.51       259\n",
      "weighted avg       0.55      0.55      0.51       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.6212\n",
      "- Recall: 0.6048\n",
      "- F1 score: 0.5674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.85      0.65      0.74        26\n",
      "    low risk       0.51      0.95      0.67        20\n",
      "    mid risk       0.50      0.21      0.30        19\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.62      0.60      0.57        65\n",
      "weighted avg       0.64      0.62      0.59        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "K nearest Classifier\n",
      "Model performance for Training set\n",
      "- Precision: 0.6763\n",
      "- Recall: 0.6804\n",
      "- F1 Score 0.6718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.77      0.81      0.79        86\n",
      "    low risk       0.63      0.77      0.69        86\n",
      "    mid risk       0.62      0.46      0.53        87\n",
      "\n",
      "    accuracy                           0.68       259\n",
      "   macro avg       0.68      0.68      0.67       259\n",
      "weighted avg       0.68      0.68      0.67       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.5192\n",
      "- Recall: 0.5394\n",
      "- F1 score: 0.5261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.75      0.81      0.78        26\n",
      "    low risk       0.52      0.60      0.56        20\n",
      "    mid risk       0.29      0.21      0.24        19\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.52      0.54      0.53        65\n",
      "weighted avg       0.54      0.57      0.55        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "Model performance for Training set\n",
      "- Precision: 0.9527\n",
      "- Recall: 0.9501\n",
      "- F1 Score 0.9493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.92      1.00      0.96        86\n",
      "    low risk       0.93      0.98      0.95        86\n",
      "    mid risk       1.00      0.87      0.93        87\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.5024\n",
      "- Recall: 0.4446\n",
      "- F1 score: 0.4614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.89      0.62      0.73        26\n",
      "    low risk       0.37      0.35      0.36        20\n",
      "    mid risk       0.25      0.37      0.30        19\n",
      "\n",
      "    accuracy                           0.46        65\n",
      "   macro avg       0.50      0.44      0.46        65\n",
      "weighted avg       0.54      0.46      0.49        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "- Precision: 0.9500\n",
      "- Recall: 0.9499\n",
      "- F1 Score 0.9498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.95      0.98      0.97        86\n",
      "    low risk       0.96      0.94      0.95        86\n",
      "    mid risk       0.93      0.93      0.93        87\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.5611\n",
      "- Recall: 0.5497\n",
      "- F1 score: 0.5540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.83      0.73      0.78        26\n",
      "    low risk       0.52      0.55      0.54        20\n",
      "    mid risk       0.33      0.37      0.35        19\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.56      0.55      0.55        65\n",
      "weighted avg       0.59      0.57      0.58        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "Model performance for Training set\n",
      "- Precision: 0.9117\n",
      "- Recall: 0.9115\n",
      "- F1 Score 0.9109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.95      0.95      0.95        86\n",
      "    low risk       0.88      0.94      0.91        86\n",
      "    mid risk       0.90      0.84      0.87        87\n",
      "\n",
      "    accuracy                           0.91       259\n",
      "   macro avg       0.91      0.91      0.91       259\n",
      "weighted avg       0.91      0.91      0.91       259\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Precision: 0.5310\n",
      "- Recall: 0.5352\n",
      "- F1 score: 0.5316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high risk       0.75      0.69      0.72        26\n",
      "    low risk       0.57      0.65      0.60        20\n",
      "    mid risk       0.28      0.26      0.27        19\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.53      0.54      0.53        65\n",
      "weighted avg       0.56      0.55      0.55        65\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight= 'balanced'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"K nearest Classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(class_weight= 'balanced'),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(class_weight= 'balanced'),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    # \"XGBoost Classifier\": XGBClassifier(),\n",
    "    \n",
    "}\n",
    "\n",
    "model_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_precision, model_train_recall, model_train_f1 = model_evaluator(y_train, y_train_pred)\n",
    "    model_test_precision, model_test_recall, model_test_f1 = model_evaluator(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Precision: {:.4f}\".format(model_train_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_train_recall))\n",
    "    print(\"- F1 Score {:.4f}\".format(model_train_f1))\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Precision: {:.4f}\".format(model_test_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_test_recall))\n",
    "    print(\"- F1 score: {:.4f}\".format(model_test_f1))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    precision_list.append(model_test_precision)\n",
    "    recall_list.append(model_test_recall)\n",
    "    f1_list.append(model_test_f1)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
